---
share: true
created: 2025-05-26T19:55
updated: 2025-06-17T13:51
---
Khái niệm:: 
If not “hallucinate,” then what? If we wanted to stick with the parlance of psychiatric medicine, “confabulation” would be a more apt term. A confabulation occurs when a person unknowingly produces a false recollection, as a way of backfilling a gap in their memory. Used to describe the falsehoods of large language models, this term marches us closer to what actually is going wrong: It’s not that the model is suffering errors of perception; it’s attempting to paper over the gaps in a corpus of training data that can’t possibly span every scenario it might encounter.
Nguồn:: [ChatGPT Isn’t ‘Hallucinating.’ It’s Bullshitting.](https://undark.org/2023/04/06/chatgpt-isnt-hallucinating-its-bullshitting/)