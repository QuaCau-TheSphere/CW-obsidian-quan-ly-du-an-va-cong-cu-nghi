---
share: true
created: 2025-06-15T11:49
updated: 2025-06-15T11:49
---
[LLM không học. Nó chỉ được tối ưu hoá trong một tập điều kiện](./LLM%20kh%C3%B4ng%20h%E1%BB%8Dc.%20N%C3%B3%20ch%E1%BB%89%20%C4%91%C6%B0%E1%BB%A3c%20t%E1%BB%91i%20%C6%B0u%20ho%C3%A1%20trong%20m%E1%BB%99t%20t%E1%BA%ADp%20%C4%91i%E1%BB%81u%20ki%E1%BB%87n.md)
Learning is a helpful metaphor for what LLMs and diffusion models do. However, there is a distinction between the _metaphor_ of learning and the _process_ we describe with that metaphor. For one, a model doesn’t exist until it has “learned,” which is quite different from what we do as people: a student exists, and then goes to school, and then learns, using a mind that was already there. We value a student’s ability to learn because people have intrinsic value.

By contrast, a Large Language Model is a statistical model of the language contained within pre-selected training data. The model is a result of that training. As such, it does not “learn” but is created through data analysis. A similar shorthand describes evolution through natural selection: we might say that moths have “learned” to develop specific patterns on their wings because of their environment. We are more resilient to that idea because we know that moths have not been collectively informed about the state of the world to _decide_ the colors of their wings.

Like the moth, an AI model is better described as becoming _optimized to a set of conditions_ in which specific patterns are reinforced. Many a joker will suggest that this is also what school was, but it’s fundamentally different. Humans can exercise choice and agency over their learning and even decide to reject it. Learning from natural selection is distinct from education: nobody ever says moths or AI systems were _educated_. Yet, AI advocates want to apply educational freedom (the “right to learn”) to the companies that build Diffusion and Large Language Models.

It is not the case that “AI gathers data from the Web and learns from it.” The reality is that AI companies gather data and then optimize models to reproduce representations of that data for profit. It’s worth preserving distinctions between the process behind building software systems and the social investments that aim to cultivate the human mind.

Human learning is based on a pro-social myth: individually and collectively, human minds hold more social value than any corporation’s product development cycle. The learning myth aims to promote the equivalence between computer systems and human thought and establish these activities on equal footing within the eyes of the law, policy, and consumers. It supports a fantastic representation of the AI system as having human-like capabilities and social value, essential to selling it to people to do human-like things. But AI products do not _learn_ from our data — they cannot exist without it.

The learning myth downplays the role of data in developing these systems, perpetuating a related myth that data is abundant, cheap, and labor-free. These myths drive down the value of data while [hiding the work](https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence/) of those who shape, define, and label that data. The existence of this labor can sully the tech industry’s myth of representing progress and justice through technology. The AI industry is a data industry. The less we can see the costs associated with hoarding that data, the easier for companies to justify it.

Trích từ:: [Challenging The Myths of Generative AI \| TechPolicy.Press](https://www.techpolicy.press/challenging-the-myths-of-generative-ai/)